C'est naturel d'essaier de deviner le prochain mot suivant une séquence. 

Les modèles qui associent une probabilité à chaque mot qui pourrait suivre s'appellent "language models" (LM).
Les LLM qu'on utilisent aujourd'hui font ça aussi. 

LM peuvent aussi attribuer une probabilité à une phrase entière. 
	[exemple d'une phrase naturelle]
	[exemple d'une phrase pas naturelle]
	
Cette probabilité nous permet de choisir la MEILLEURE option, l'option la plus probable, la plus correcte. 
Pour les correcteurs de grammaire : 
	THEIR are two midterms.
	Everything has IMPROVE.
Ou pour la recognition de voix : 
	I will be back soonish, pas I will be bassoon dish. 
	
Language models can also help in augmentative and
alternative communication systems (Trnka et al. 2007, Kane et al. 2017). People
often use such AAC devices if they are physically unable to speak or sign but canAAC
instead use eye gaze or other specific movements to select words from a menu. Word
prediction can be used to suggest likely words for the menu

C'est quoi un bigram, trigram, ngram

P(mot|histoire) ? 
Une façon naive de faire : relative frequency counts. 

Un peu de notation pour introduire le truc. On peut pas compter le nombre de fois que le mot suit 
une histoire, car y'a trop de possibilité d'histoires. Probabilités conditionnelles n'aide pas trop non-plus, 
toujours trop de trucs à calculer. Markov assumption. On peut prédire un truc en regardant pas trop loin 
dans le passé. 

Exemple de bigram peut-être, mentionner qu'on utilise des log probabilités. 
Dire que les probabilités nous apprennent des informations purement grammaticales, mais aussi 
des relations sur le monde réel. Chinese food vs English food. 

Extrinsic evaluation : évaluation d'un modèle dans la vraie vie. 
Intrinsic evaluation : une métrique permettant d'évaluer le modèle sans le lancer dans la vraie vie. 

Training set, development set, test set.

An (intrinsic) improvement in perplexity does not guarantee an (extrinsic) im-
provement in the performance of a language processing task like speech recognition
or machine translation. Nonetheless, because perplexity usually correlates with task
improvements, it is commonly used as a convenient evaluation metric. Still, when
possible a model’s improvement in perplexity should be confirmed by an end-to-end
evaluation on a real task.



